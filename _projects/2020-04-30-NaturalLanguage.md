---
title: 'Deep Learning Model for Natural Language Translation'
date: 2020-04-30 00:00:00
featured_image: '/images/language.jpg'
excerpt: The project team engineered deep learning models for natural language translation (Portuguese to English). We developed a seq2seq model with Long Short-term Memory (LSTM) and a Transformer model. We evaluated the models with a BLEU (Bilingual Evaluation Understudy) score, and the Transformer model scored 0.45, which was higher than the score of the seq2seq model (0.42).
---

![](/images/language.jpg)

The project team engineered deep learning models for natural language translation (Portuguese to English). We developed a seq2seq model with Long Short-term Memory (LSTM) and a Transformer model. We evaluated the models with a BLEU (Bilingual Evaluation Understudy) score, and the Transformer model scored 0.45, which was higher than the score of the seq2seq model (0.42).

The presentation file is available [here](https://drive.google.com/file/d/1uzw-Ng8xgfAjoPCc6dNnWGeeXlAfE3KC/view?usp=drive_link).
